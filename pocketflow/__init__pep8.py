"""
Flow Framework - A lightweight framework for creating and executing workflows.

This library provides a set of classes for building computational workflows where
nodes can be connected together to form a directed graph. Each node can process data
and determine which node should be executed next.

Generated by Claude 3.7 Sonnet on 2025-04-30:
https://claude.ai/chat/ae86176b-bec5-4f9d-9f18-295c0c263e48
"""

import asyncio
import warnings
import copy
import time


class BaseNode:
    """
    Base class for all nodes in the flow framework.
    
    Provides core functionality for node connections, parameter management,
    and execution flow. Serves as the foundation for other node types.
    """
    
    def __init__(self):
        """Initialize a node with empty params and successors dictionaries."""
        self.params = {}
        self.successors = {}
    
    def set_params(self, params):
        """Set the parameters for this node."""
        self.params = params
    
    def next(self, node, action="default"):
        """
        Connect this node to another node with a specific action.
        
        Args:
            node: The successor node to connect to
            action: The action name that triggers this connection
            
        Returns:
            The successor node for easy chaining
        """
        if action in self.successors:
            warnings.warn(f"Overwriting successor for action '{action}'")
        self.successors[action] = node
        return node
    
    def prep(self, shared):
        """
        Prepare node for execution.
        
        Args:
            shared: Shared context data
            
        Returns:
            Preparation results to be passed to exec
        """
        pass
    
    def exec(self, prep_res):
        """
        Execute node logic.
        
        Args:
            prep_res: Results from the prep stage
            
        Returns:
            Execution results
        """
        pass
    
    def post(self, shared, prep_res, exec_res):
        """
        Post-processing after execution.
        
        Args:
            shared: Shared context data
            prep_res: Results from the prep stage
            exec_res: Results from the exec stage
            
        Returns:
            Final results after post-processing
        """
        pass
    
    def _exec(self, prep_res):
        """Internal method to execute the node logic."""
        return self.exec(prep_res)
    
    def _run(self, shared):
        """
        Internal method to run the full node execution cycle.
        
        Args:
            shared: Shared context data
            
        Returns:
            Results after the full execution cycle
        """
        p = self.prep(shared)
        e = self._exec(p)
        return self.post(shared, p, e)
    
    def run(self, shared):
        """
        Public method to run this node.
        
        Args:
            shared: Shared context data
            
        Returns:
            Results after execution
        """
        if self.successors:
            warnings.warn("Node won't run successors. Use Flow.")
        return self._run(shared)
    
    def __rshift__(self, other):
        """Override >> operator for creating node connections."""
        return self.next(other)
    
    def __sub__(self, action):
        """
        Override - operator for conditional transitions.
        
        Args:
            action: The action name as a string
            
        Returns:
            ConditionalTransition object
            
        Raises:
            TypeError: If action is not a string
        """
        if isinstance(action, str):
            return _ConditionalTransition(self, action)
        raise TypeError("Action must be a string")


class _ConditionalTransition:
    """
    Helper class for conditional transitions between nodes.
    
    Used to create connections with specific action names.
    """
    
    def __init__(self, src, action):
        """
        Initialize a conditional transition.
        
        Args:
            src: Source node
            action: Action name
        """
        self.src = src
        self.action = action
    
    def __rshift__(self, tgt):
        """
        Override >> operator to complete the conditional connection.
        
        Args:
            tgt: Target node
            
        Returns:
            Target node
        """
        return self.src.next(tgt, self.action)


class Node(BaseNode):
    """
    Standard node with retry functionality.
    
    Extends BaseNode with the ability to retry execution on failure.
    """
    
    def __init__(self, max_retries=1, wait=0):
        """
        Initialize a node with retry capabilities.
        
        Args:
            max_retries: Maximum number of execution attempts
            wait: Time to wait between retries in seconds
        """
        super().__init__()
        self.max_retries = max_retries
        self.wait = wait
    
    def exec_fallback(self, prep_res, exc):
        """
        Fallback method called when all retries are exhausted.
        
        Args:
            prep_res: Results from preparation
            exc: The exception that caused the failure
            
        Raises:
            The exception by default
        """
        raise exc
    
    def _exec(self, prep_res):
        """
        Internal execution with retry logic.
        
        Args:
            prep_res: Results from preparation
            
        Returns:
            Execution results or fallback results
        """
        for self.cur_retry in range(self.max_retries):
            try:
                return self.exec(prep_res)
            except Exception as e:
                if self.cur_retry == self.max_retries - 1:
                    return self.exec_fallback(prep_res, e)
                if self.wait > 0:
                    time.sleep(self.wait)


class BatchNode(Node):
    """
    Node that processes a batch of items.
    
    Applies the node's execution logic to each item in a batch.
    """
    
    def _exec(self, items):
        """
        Execute the node logic on each item in the batch.
        
        Args:
            items: List of items to process
            
        Returns:
            List of execution results
        """
        return [super(BatchNode, self)._exec(i) for i in (items or [])]


class Flow(BaseNode):
    """
    Orchestrates execution of multiple connected nodes.
    
    Manages the flow of execution from a starting node through its successors.
    """
    
    def __init__(self, start=None):
        """
        Initialize a flow with an optional starting node.
        
        Args:
            start: The starting node of the flow
        """
        super().__init__()
        self.start_node = start
    
    def start(self, start):
        """
        Set the starting node for this flow.
        
        Args:
            start: The node to set as the starting point
            
        Returns:
            The starting node for chaining
        """
        self.start_node = start
        return start
    
    def get_next_node(self, curr, action):
        """
        Find the next node to execute based on the current action.
        
        Args:
            curr: Current node
            action: The action that determines the next node
            
        Returns:
            The next node or None if no successor exists
        """
        nxt = curr.successors.get(action or "default")
        if not nxt and curr.successors:
            warnings.warn(f"Flow ends: '{action}' not found in {list(curr.successors)}")
        return nxt
    
    def _orch(self, shared, params=None):
        """
        Orchestrate the execution of nodes in the flow.
        
        Args:
            shared: Shared context data
            params: Optional parameters to start with
            
        Returns:
            The last action returned by the final node
        """
        curr = copy.copy(self.start_node)
        p = params or {**self.params}
        last_action = None
        
        while curr:
            curr.set_params(p)
            last_action = curr._run(shared)
            curr = copy.copy(self.get_next_node(curr, last_action))
        
        return last_action
    
    def _run(self, shared):
        """Run the entire flow."""
        p = self.prep(shared)
        o = self._orch(shared)
        return self.post(shared, p, o)
    
    def post(self, shared, prep_res, exec_res):
        """Return the final result of the flow execution."""
        return exec_res


class BatchFlow(Flow):
    """
    A flow that processes batches of parameters.
    
    Executes the flow multiple times, once for each set of parameters.
    """
    
    def _run(self, shared):
        """
        Run the flow for each set of parameters in the batch.
        
        Args:
            shared: Shared context data
            
        Returns:
            The result of post-processing
        """
        pr = self.prep(shared) or []
        
        for bp in pr:
            self._orch(shared, {**self.params, **bp})
        
        return self.post(shared, pr, None)


class AsyncNode(Node):
    """
    Node with asynchronous execution capabilities.
    
    Provides async versions of node methods for use in async workflows.
    """
    
    async def prep_async(self, shared):
        """Async preparation."""
        pass
    
    async def exec_async(self, prep_res):
        """Async execution."""
        pass
    
    async def exec_fallback_async(self, prep_res, exc):
        """Async fallback on failure."""
        raise exc
    
    async def post_async(self, shared, prep_res, exec_res):
        """Async post-processing."""
        pass
    
    async def _exec(self, prep_res):
        """
        Async execution with retry logic.
        
        Args:
            prep_res: Results from preparation
            
        Returns:
            Execution results or fallback results
        """
        for i in range(self.max_retries):
            try:
                return await self.exec_async(prep_res)
            except Exception as e:
                if i == self.max_retries - 1:
                    return await self.exec_fallback_async(prep_res, e)
                if self.wait > 0:
                    await asyncio.sleep(self.wait)
    
    async def run_async(self, shared):
        """Public method to run this async node."""
        if self.successors:
            warnings.warn("Node won't run successors. Use AsyncFlow.")
        return await self._run_async(shared)
    
    async def _run_async(self, shared):
        """Internal method to run the full async execution cycle."""
        p = await self.prep_async(shared)
        e = await self._exec(p)
        return await self.post_async(shared, p, e)
    
    def _run(self, shared):
        """
        Override synchronous run to prevent misuse.
        
        Raises:
            RuntimeError: Always raised to prevent misuse
        """
        raise RuntimeError("Use run_async.")


class AsyncBatchNode(AsyncNode, BatchNode):
    """
    Asynchronous node that processes items in sequence.
    
    Combines AsyncNode and BatchNode functionality for sequential processing.
    """
    
    async def _exec(self, items):
        """Process batch items sequentially with async execution."""
        return [await super(AsyncBatchNode, self)._exec(i) for i in items]


class AsyncParallelBatchNode(AsyncNode, BatchNode):
    """
    Asynchronous node that processes items in parallel.
    
    Processes all items in the batch concurrently.
    """
    
    async def _exec(self, items):
        """Process batch items in parallel with async execution."""
        return await asyncio.gather(*(super(AsyncParallelBatchNode, self)._exec(i) for i in items))


class AsyncFlow(Flow, AsyncNode):
    """
    Asynchronous flow for orchestrating async nodes.
    
    Manages asynchronous execution of a flow of nodes.
    """
    
    async def _orch_async(self, shared, params=None):
        """
        Orchestrate async execution of nodes in the flow.
        
        Args:
            shared: Shared context data
            params: Optional parameters to start with
            
        Returns:
            The last action returned by the final node
        """
        curr = copy.copy(self.start_node)
        p = params or {**self.params}
        last_action = None
        
        while curr:
            curr.set_params(p)
            if isinstance(curr, AsyncNode):
                last_action = await curr._run_async(shared)
            else:
                last_action = curr._run(shared)
            curr = copy.copy(self.get_next_node(curr, last_action))
        
        return last_action
    
    async def _run_async(self, shared):
        """Run the entire async flow."""
        p = await self.prep_async(shared)
        o = await self._orch_async(shared)
        return await self.post_async(shared, p, o)
    
    async def post_async(self, shared, prep_res, exec_res):
        """Return the final result of the async flow execution."""
        return exec_res


class AsyncBatchFlow(AsyncFlow, BatchFlow):
    """
    Asynchronous flow that processes batches sequentially.
    
    Executes the async flow for each set of parameters in sequence.
    """
    
    async def _run_async(self, shared):
        """
        Run the async flow for each set of parameters in the batch.
        
        Args:
            shared: Shared context data
            
        Returns:
            The result of post-processing
        """
        pr = await self.prep_async(shared) or []
        
        for bp in pr:
            await self._orch_async(shared, {**self.params, **bp})
        
        return await self.post_async(shared, pr, None)


class AsyncParallelBatchFlow(AsyncFlow, BatchFlow):
    """
    Asynchronous flow that processes batches in parallel.
    
    Executes the async flow for all parameter sets concurrently.
    """
    
    async def _run_async(self, shared):
        """
        Run the async flow for all parameter sets in parallel.
        
        Args:
            shared: Shared context data
            
        Returns:
            The result of post-processing
        """
        pr = await self.prep_async(shared) or []
        
        await asyncio.gather(*(self._orch_async(shared, {**self.params, **bp}) for bp in pr))
        
        return await self.post_async(shared, pr, None)